title Tạo Câu Trả Lời - Sequence Diagram

frame "Tạo Câu Trả Lời"
actor Agent
boundary "AnswerGenerationService (API)" as API
control "PromptBuilder" as PB
control "LLM Client (Groq)" as LLM
database "Groq API" as GROQ

Agent->API: Yêu cầu tạo câu trả lời\n(query, context_chunks, selected_file)
API->API: Kiểm tra context_chunks có rỗng không
alt Context chunks rỗng
    API-->Agent: Response (message: "Trong các tài liệu đã upload chưa có thông tin về nội dung này.")
else Context chunks không rỗng
    API->PB: Nhóm chunks và tạo context_text
    PB->PB: Nhóm chunks theo file và page\nSắp xếp và kết hợp texts
    PB-->API: context_text
    
    API->PB: Tạo prompt với query, context_text, selected_file
    PB->PB: Tạo prompt template với yêu cầu chi tiết
    PB-->API: prompt
    
    API->API: Kiểm tra llm_client có tồn tại không
    alt LLM client không tồn tại
        API-->Agent: Response (message: "Chưa cấu hình LLM API key" + context_text)
    else LLM client tồn tại
        API->LLM: generate_answer(prompt)
        LLM->LLM: Kiểm tra llm_provider
        alt Provider không được hỗ trợ
            LLM-->API: Error
            API-->Agent: Response (message: "LLM provider không được hỗ trợ" + context_text)
        else Provider là Groq
            LLM->GROQ: chat.completions.create(model, messages, max_tokens=4096)
            GROQ->GROQ: Xử lý prompt và tạo câu trả lời
            alt Model không khả dụng
                GROQ-->LLM: Exception
                LLM->LLM: Thử model dự phòng
                loop Với mỗi fallback_model
                    LLM->GROQ: chat.completions.create(fallback_model, ...)
                    alt Thành công
                        GROQ-->LLM: response với answer
                        break
                    else Lỗi
                        GROQ-->LLM: Exception
                    end
                end
                alt Tất cả models đều lỗi
                    LLM-->API: Exception
                    API-->Agent: Response (message: "Lỗi khi tạo câu trả lời" + context_text)
                else Có model thành công
                    LLM-->API: answer
                end
            else Model chính thành công
                GROQ-->LLM: response với answer
                LLM->LLM: Kiểm tra answer có bị cắt cụt không\nNếu có, retry với max_tokens=8192
                LLM-->API: answer
            end
            API->API: Format và làm sạch answer
            API-->Agent: Response (success: true, answer)
        end
    end
end
end
